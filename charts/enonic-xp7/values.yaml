
# Which Docker image will be used
image:
  repository: enonic/xp
  tag: "7.4.1-ubuntu"
  pullPolicy: IfNotPresent # See https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy

# Hard set the Enonic XP SuperUser password
suPassword: changeme

# Settings of the bucket which the .jar will be downloaded
JarSpecs:
  prefix: "sample-project-" # Jar name without the version and the extension
  name: sample-project-1.1.0.jar # Full jar name
  bucketOptions:
    secret: bucket-secret # Name of the secret that contains the bucket credentials
    url: s3.example.com # Bucket URL
    suffix: sample-project/staging # Bucket folder where the jar file is located

# Setup the SMTP container
smtp:
  enabled: false
  image: ixdotai/smtp # Docker image for the SMTP container

# Setup environment variables to be used inside the Enonic XP container
envVars: []
#   - name: JAVA_OPTS
#     value: -Xms2G -Xmx2G

# Enonic app health check settings (Do not decrease it)
probes:
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 2

# Determines how many time the application has to shutdown when required
terminationGracePeriodSeconds: 180

# Self explanatory
replicaCount: 1

# Set annotations to the StatefulSet
annotations: {}

# Set labels to the StatefulSet
labels: {}

# Set annotations to the Enonic Xp app pod
podAnnotations: {}

# Set labels to the Enonic Xp app pod
podLabels: {}

# An array of names of Docker registry credential secrets
imagePullSecrets: []
  # - name: example-secret


# Its highly recommended to set limits and requests for memory.
# You don't need to set CPU only if the app usually stays idle for a considered time.
# If you do want to specify resources, uncomment the following lines, 
# adjust them as necessary, and remove the curly braces after 'resources:'.
resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 1000Mi
  # requests:
  #   cpu: 100m
  #   memory: 1000Mi

# This will prevent the application to run on weak machines.
# See: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
nodeSelector: {}
  # node: workloads

# This will tell to kubernetes to schedule this application on a node even
# if the followed rules are true.
# See: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration
tolerations: []
  # - key: "dedicated"
  #   operator: "Equal"
  #   value: "workloads"
  #   effect: "NoSchedule"


# See: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
affinity: {}

securityContext:
  fsGroup: 2000
  fsGroupChangePolicy: "OnRootMismatch"

containerSecurityContext:
  runAsNonRoot: true
  runAsUser: 1337

# Storage Volumes settings 
volumeSpec:
  # It will use NFS storage class by default, which is a shared storage provider. This also supports volume resize.
  # If you don't know what a storage class is, see https://kubernetes.io/docs/concepts/storage/storage-classes/#introduction
  # Resuming, a storage class will handle the creation of those persistent storage volumes with the desired capacity.
  storageClass: "efs-sc" # Needs to support ReadWriteMany
  persistentIndexes: true # Enable persistent volume to store ElasticSearch unshared indexes (Recommended)
  indexStorageClass: "ebs-sc" # Needs to support ReadWriteOnly
  sizes:
    blobs: 3Gi # Enonic data storage (ElasticSearch shared indexes)
    data: 3Gi # Enonic Data toolbox folder
    snapshots: 3Gi # Data snapshots folder
    deploy: 100Mi # Deploy folder
    # index: 3Gi # ElasticSearch unshared indexes (Default will be same as blobs)


# Reverse proxy settings
ingress:
  ssl: true # If you want SSL to your domain or not
  sslIssuer: "letsencrypt-prod" # See https://cert-manager.io/docs/concepts/issuer/
  redirectFromWWW: true # If you want redirect www URLs to non-www URLs
  preventIndexing: true # Enable it to add headers and robots.txt to prevent indexing
  maxBodySize: 1000m # client_max_body_size directive. See https://www.tecmint.com/limit-file-upload-size-in-nginx/
  hosts:
    # Listing which domains you want to be able to hit the application
    - host: app.example.com
    # - host: localhost
    #   ssl: false

# Enonic XP vhosts configuration
# See: https://developer.enonic.com/docs/xp/stable/deployment/config#vhost
vhosts: |-
  enabled = false

  mapping.site.host = app.example.com
  mapping.site.source = /
  mapping.site.target = /site/default/master/example

  mapping.admin.host = app.example.com
  mapping.admin.source = /admin
  mapping.admin.target = /admin
  mapping.admin.idProvider.system = default

# Additional config entries to com.enonic.xp.elasticsearch.cfg
# See: https://developer.enonic.com/docs/xp/stable/deployment/config#elasticsearch
# DO NOT override the "discovery.unicast.sockets" directive
# Also is not recommended to override either "node.data" or "node.master" directive.
customESConfigs: ""
# customESConfigs: |-
#   index.max_result_window = 2147483647


# Override the entire logback.xml file
# See https://developer.enonic.com/docs/xp/stable/deployment/config#logging
loggingConfigOverride: ""
# loggingConfigOverride: |-
#   <?xml version="1.0"?>
#   <configuration scan="true" scanPeriod="60 seconds">

#   </configuration>

# A simple way to configure logback.xml
customLoggingConfigs:
  defaultFormat: '%date{ISO8601} %-5level %logger{36} - %msg%n' # Default logging format
  fileAppender:
    enabled: true # Enable logging to a file inside the /logs folder
    format: '%date{ISO8601} %-5level %logger{36} - %msg%n' # File logging format
    maxSize: 100MB # Max logging file size
    maxHistory: 2 # Max stored logging files
    totalSizeCap: 200MB # Max total size of all stored logging files

# Additional configuration files
# See https://developer.enonic.com/docs/xp/stable/deployment/config
# DO NOT OVERRIDE ANY OF THESE FOLLOWING FILES: 
# com.enonic.xp.cluster.cfg, com.enonic.xp.elasticsearch.cfg, 
# com.enonic.xp.hazelcast.cfg, com.enonic.xp.web.sessionstore.cfg, 
# system.properties, com.enonic.xp.web.vhost.cfg and logback.xml
customEnonicConfigs: {}
  # com.enonic.xp.mail.cfg: |-
  #   smtpHost=smtp.gmail.com
  #   smtpPort=587
  #   smtpAuth=true
  #   smtpUser=test@test.com
  #   smtpPassword=password
  #   smtpTLS=true


# KEDA support. See https://keda.sh/
# It creates a ScaledObject like on https://keda.sh/docs/2.4/concepts/scaling-deployments/
# Basically it allows the application to be turned off in case of inativity
keda:
  enabled: false
  settings:
    # pollingInterval:  30                               # Optional. Default: 30 seconds
    # cooldownPeriod:   300                              # Optional. Default: 300 seconds
    # idleReplicaCount: 0                                # Optional. Must be less than minReplicaCount
    # minReplicaCount:  1                                # Optional. Default: 0
    maxReplicaCount:  1                                  # Optional. Default: 100
    # fallback:                                          # Optional. Section to specify fallback options
    #   failureThreshold: 3                              # Mandatory if fallback section is included
    #   replicas: 6                                      # Mandatory if fallback section is included
    # advanced:                                          # Optional. Section to specify advanced options
    #   restoreToOriginalReplicaCount: true/false        # Optional. Default: false
    #   horizontalPodAutoscalerConfig:                   # Optional. Section to specify HPA related options
    #     behavior:                                      # Optional. Use to modify HPA's scaling behavior
    #       scaleDown:
    #         stabilizationWindowSeconds: 300
    #         policies:
    #         - type: Percent
    #           value: 100
    #           periodSeconds: 15
  # If any trigger is provided, a Prometheus trigger will be used with the following
  # access URL and the "nginx_ingress_controller_requests" metric, which will tell KEDA
  # if the application is being used or not (regardless of how many requests).
  # This approach is used just to avoid idle applications from
  # spending resources unnecessarily
  defaultPrometheusURL: "http://prometheus.prometheus.svc.cluster.local"
  triggers: []
    # - type: prometheus
    #   metadata:
    #     serverAddress: "http://prometheus.kube-system.svc.cluster.local"
    #     metricName: http_total_requests
    #     query: sum(rate(nginx_ingress_controller_requests{namespace='enonic-review', service="nhn-service"}[2m]))*500
    #     threshold: '1'

